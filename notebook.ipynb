{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/Users/jmtek/audio-orchestrator-ffmpeg/bin:$PATH\n"
     ]
    }
   ],
   "source": [
    "%env PATH=/Users/jmtek/audio-orchestrator-ffmpeg/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m# import os\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[39m# os.environ['FFMPEG_BINARY'] = '/Users/jmtek/audio-orchestrator-ffmpeg/bin'\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[39m=\u001b[39m whisper\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39msmall\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtranscribe(\u001b[39m\"\u001b[39;49m\u001b[39mstatic/sample.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m, fp16\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(result)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtext:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m result[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/transcribe.py:121\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    118\u001b[0m     decode_options[\u001b[39m\"\u001b[39m\u001b[39mfp16\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m mel \u001b[39m=\u001b[39m log_mel_spectrogram(audio, padding\u001b[39m=\u001b[39;49mN_SAMPLES)\n\u001b[1;32m    122\u001b[0m content_frames \u001b[39m=\u001b[39m mel\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m N_FRAMES\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m decode_options\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[0;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(audio):\n\u001b[1;32m    139\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(audio, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m         audio \u001b[39m=\u001b[39m load_audio(audio)\n\u001b[1;32m    141\u001b[0m     audio \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(audio)\n\u001b[1;32m    143\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/whisper/audio.py:59\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# fmt: on\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     out \u001b[39m=\u001b[39m run(cmd, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mstdout\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m CalledProcessError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to load audio: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mdecode()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    972\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    973\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    974\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    975\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    976\u001b[0m                         errread, errwrite,\n\u001b[1;32m    977\u001b[0m                         restore_signals,\n\u001b[1;32m    978\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    979\u001b[0m                         start_new_session)\n\u001b[1;32m    980\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:1803\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1801\u001b[0m errpipe_data \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m()\n\u001b[1;32m   1802\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1803\u001b[0m     part \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mread(errpipe_read, \u001b[39m50000\u001b[39;49m)\n\u001b[1;32m   1804\u001b[0m     errpipe_data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m part\n\u001b[1;32m   1805\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m part \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(errpipe_data) \u001b[39m>\u001b[39m \u001b[39m50000\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "# import os\n",
    "\n",
    "# os.environ['FFMPEG_BINARY'] = '/Users/jmtek/audio-orchestrator-ffmpeg/bin'\n",
    "\n",
    "model = whisper.load_model(\"small\")\n",
    "result = model.transcribe(\"static/sample.wav\", fp16=False)\n",
    "print(result)\n",
    "\n",
    "print(\"text:\\n\\n\" + result[\"text\"])\n",
    "print(\"segments:\\n\\n\" + str(result[\"segments\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://jmtek-whisper.hf.space ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[00:00:00 --> 00:00:02]  不让你发现没有\\n[00:00:02 --> 00:00:04]  独立思想\\n[00:00:04 --> 00:00:09]  在很多学校里面是能够让校长血压飙升的毒药\\n[00:00:09 --> 00:00:12]  最近这段时间关于人工智能的新闻\\n[00:00:12 --> 00:00:15]  越来越快的迭代速度\\n[00:00:15 --> 00:00:17]  让我们很多人意识到\\n[00:00:17 --> 00:00:20]  他们的工作有可能要被AI替代了\\n[00:00:20 --> 00:00:23]  但是我们的孩子却继续在学校里\\n[00:00:23 --> 00:00:26]  接受着传统的硬实教育\\n[00:00:26 --> 00:00:29]  可能大概率就是白学\\n[00:00:29 --> 00:00:32]  而那些搞教育的决策者们\\n[00:00:32 --> 00:00:34]  号称一直在改革\\n[00:00:34 --> 00:00:37]  我不知道他们打算找什么样的借口\\n[00:00:37 --> 00:00:39]  继续躲避下去\\n[00:00:39 --> 00:00:41]  我们必须得重新思考\\n[00:00:41 --> 00:00:45]  我们教育内核里面缺了哪些东西\\n[00:00:45 --> 00:00:47]  我的观点就是说\\n[00:00:47 --> 00:00:49]  最重要的一个缺失点就是\\n[00:00:49 --> 00:00:53]  我们没有呵护好孩子探究的能力\\n[00:00:53 --> 00:00:56]  这其实是一种语生俱来的能力\\n[00:00:56 --> 00:00:58]  而且他不需培养\\n[00:00:58 --> 00:01:00]  只需要呵护就可以\\n[00:01:00 --> 00:01:02]  而反观我们的教育\\n[00:01:02 --> 00:01:04]  还停留在上个世纪\\n[00:01:04 --> 00:01:08]  你看一下我们大学中学小学的课本\\n[00:01:08 --> 00:01:09]  教学大纲\\n[00:01:09 --> 00:01:12]  全是农耕时代和大工业时代的\\n[00:01:12 --> 00:01:13]  成就知识\\n[00:01:13 --> 00:01:16]  这些都称不上是知识了\\n[00:01:16 --> 00:01:18]  严重智候不说\\n[00:01:18 --> 00:01:21]  整齐化医 高重复\\n[00:01:21 --> 00:01:24]  重视灌输的这种硬实教育\\n[00:01:24 --> 00:01:27]  极度的压抑好奇心\\n[00:01:27 --> 00:01:30]  探索和其思妙想\\n[00:01:30 --> 00:01:32]  统一教材 统一规划\\n[00:01:32 --> 00:01:34]  然后把认知也给统一了\\n[00:01:34 --> 00:01:36]  然后把教育资源和社会资源\\n[00:01:36 --> 00:01:38]  又统一起来\\n[00:01:38 --> 00:01:42]  最后用高考这个怪胎来去统一分配\\n[00:01:42 --> 00:01:44]  荒诞\\n[00:01:44 --> 00:01:47]  在这种异化的教育下\\n[00:01:47 --> 00:01:50]  我们很多孩子已经放弃主动思考了\\n[00:01:50 --> 00:01:53]  都成了听话的乖乖仔\\n[00:01:53 --> 00:01:55]  我们太多的家长也不知道\\n[00:01:55 --> 00:01:58]  我们家的孩子来的什么样的人才会吃香\\n[00:01:58 --> 00:02:02]  只知道研究别人家的孩子过去是怎么成功的\\n[00:02:02 --> 00:02:05]  然后误以为当下所做的那个\\n[00:02:05 --> 00:02:09]  为了高考而准备的大量的作业和考试\\n[00:02:09 --> 00:02:11]  就是教育\\n[00:02:11 --> 00:02:16]  然后对教育理念和教育资源的独立思考\\n[00:02:16 --> 00:02:18]  完全确实\\n[00:02:18 --> 00:02:20]  你要说如何破局\\n[00:02:20 --> 00:02:23]  我这里有四个观点\\n[00:02:23 --> 00:02:28]  就是未来的世界是考验家长的时代\\n[00:02:28 --> 00:02:30]  尤其在我们这儿\\n[00:02:30 --> 00:02:33]  家长的认知就会是孩子的起跑线\\n[00:02:33 --> 00:02:35]  甚至是孩子的天花板\\n[00:02:35 --> 00:02:38]  我们家长必须得懂一些教育的底层逻辑\\n[00:02:38 --> 00:02:42]  二就是我们必须得为孩子提供更多的机会\\n[00:02:42 --> 00:02:46]  去发展他们独特的天父天性和性去爱好\\n[00:02:46 --> 00:02:52]  第三就是让孩子掌握他们对个性的那种选择权\\n[00:02:52 --> 00:02:57]  让他们对未来自己有可能充当的社会角色充满期待\\n[00:02:57 --> 00:03:02]  并以未来来引导当下的学习行为\\n[00:03:02 --> 00:03:06]  第四就是一定得拥抱人工智能\\n[00:03:06 --> 00:03:09]  率先使用主流的AI工具\\n[00:03:09 --> 00:03:12]  让孩子们成为出色的使用AI的人\\n[00:03:12 --> 00:03:14]  当然也有可能包括家长\\n[00:03:14 --> 00:03:19]  如果我们把AI想象成是突然冒出来的神龙\\n[00:03:19 --> 00:03:21]  与其恐惧他们\\n[00:03:21 --> 00:03:26]  不如让孩子早些成为御龙高手\\n[00:03:26 --> 00:03:27]  好吧 今天聊这'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gradio_client import Client\n",
    "\n",
    "client = Client(\"jmtek/whisper\", hf_token=\"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\")\n",
    "\n",
    "def acapellify(audio_path):\n",
    "    result = client.predict(audio_path, api_name=\"/transcribe_audio\")\n",
    "    return result\n",
    "\n",
    "acapellify('static/upload/e07068f6-f2d6-11ed-8152-a860b631bb1c.m4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://jmtek-whisper.hf.space ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/var/folders/cw/dy6xxgm92bs6ppqm7jbgtp7w0000gn/T/usersjmtekDownloads114_1684404797c7sh0b0j.m4a'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gradio_client import Client\n",
    "\n",
    "client = Client(\"jmtek/whisper\", hf_token=\"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\")\n",
    "client.predict(\"/users/jmtek/Downloads/114_1684404797.mp4\", api_name=\"/get_audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://jmtek-whisper.hf.space ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/var/folders/cw/dy6xxgm92bs6ppqm7jbgtp7w0000gn/T/vocalskzty7nyf.mp3'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gradio_client import Client\n",
    "\n",
    "client = Client(\"jmtek/whisper\", hf_token=\"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\")\n",
    "client.predict(\"static/upload/e07068f6-f2d6-11ed-8152-a860b631bb1c.m4a\", api_name=\"/get_vocal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://jmtek-whisper.hf.space ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[00:00:00 --> 00:00:02]  哎,每天做这视频太累了\\n[00:00:02 --> 00:00:04]  要不今天还是交给我的小助理吧\\n[00:00:04 --> 00:00:07]  大家好,我是创业司机的小助理\\n[00:00:07 --> 00:00:11]  我会陪伴大家一起学习如何用了iT高10倍生产力\\n[00:00:11 --> 00:00:14]  今天的课程就是将你如何免费制作一个\\n[00:00:14 --> 00:00:17]  像我一样聪明可爱的数字小助理\\n[00:00:17 --> 00:00:17]  Let's go\\n[00:00:17 --> 00:00:20]  哈哈,我调研了各种制作AI数字人的方法\\n[00:00:20 --> 00:00:22]  终于研究出来这个可以定制头像、声音\\n[00:00:22 --> 00:00:24]  而且还完全免费的方法\\n[00:00:24 --> 00:00:27]  有一些商用软件,比如说DIID或者Synthesizer\\n[00:00:27 --> 00:00:28]  它们的效果非常不错\\n[00:00:28 --> 00:00:31]  但是成本高达每分钟3美元\\n[00:00:31 --> 00:00:33]  还有一些软件,它们只能选择固定的形象\\n[00:00:33 --> 00:00:34]  没有办法个性化定制\\n[00:00:34 --> 00:00:37]  所以这个视频你看到了就是赚到了\\n[00:00:37 --> 00:00:38]  总共分4步\\n[00:00:38 --> 00:00:40]  第一步,生成一个AI头像\\n[00:00:40 --> 00:00:41]  这个不需要我教你了吧\\n[00:00:41 --> 00:00:43]  第二步,上传到Leapix Converter\\n[00:00:43 --> 00:00:45]  生成3D动态视频\\n[00:00:45 --> 00:00:46]  增加一些动感\\n[00:00:46 --> 00:00:49]  第三步,在TTS Maker里面选择你喜欢的声音\\n[00:00:49 --> 00:00:51]  输入文字,生成语音\\n[00:00:51 --> 00:00:52]  最后一步也是最关键的一步\\n[00:00:52 --> 00:00:55]  Soso Wave to Lib,这个GitHub项目\\n[00:00:55 --> 00:00:56]  这也是一个大声开发的\\n[00:00:56 --> 00:00:58]  可以根据语音对口型的AI开源项目\\n[00:00:58 --> 00:01:00]  而且非常贴心的设置了\\n[00:01:00 --> 00:01:02]  可以在线免费运行的方式\\n[00:01:02 --> 00:01:03]  只要上传你的视频和音频\\n[00:01:03 --> 00:01:06]  一个专属于你的AI收子人就做好了\\n[00:01:06 --> 00:01:08]  关注我,每天分享音乐AI帮你提高10倍生产力\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gradio_client import Client\n",
    "\n",
    "client = Client(\"jmtek/whisper\", hf_token=\"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\")\n",
    "client.predict(\"/users/jmtek/Downloads/114_1684404797.mp4\", api_name=\"/transcribe_video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".env\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/jmtek/Work/GitHub/Demo_Video_Process/ouput/text.txt')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(\".env\")\n",
    "\n",
    "print(p.name)\n",
    "\n",
    "p = p.parent\n",
    "\n",
    "dir = \"ouput\"\n",
    "name = 'text.txt'\n",
    "p.resolve() / dir / name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-110511-g55ea1da1c0-tessus  https://evermeet.cx/ffmpeg/  Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 11.0.0 (clang-1100.0.33.17)\n",
      "  configuration: --cc=/usr/bin/clang --prefix=/opt/ffmpeg --extra-version=tessus --enable-avisynth --enable-fontconfig --enable-gpl --enable-libaom --enable-libass --enable-libbluray --enable-libdav1d --enable-libfreetype --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libmysofa --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvmaf --enable-libvo-amrwbenc --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-version3 --pkg-config-flags=--static --disable-ffplay\n",
      "  libavutil      58.  7.100 / 58.  7.100\n",
      "  libavcodec     60. 10.100 / 60. 10.100\n",
      "  libavformat    60.  5.100 / 60.  5.100\n",
      "  libavdevice    60.  2.100 / 60.  2.100\n",
      "  libavfilter     9.  7.100 /  9.  7.100\n",
      "  libswscale      7.  2.100 /  7.  2.100\n",
      "  libswresample   4. 11.100 /  4. 11.100\n",
      "  libpostproc    57.  2.100 / 57.  2.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/Users/jmtek/Downloads/113_1684404795.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isommp41mp42\n",
      "    creation_time   : 2023-05-18T10:13:13.000000Z\n",
      "    copyright       : \n",
      "    copyright-eng   : \n",
      "  Duration: 00:00:40.75, start: 0.000000, bitrate: 230 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 720x1280, 176 kb/s, 20.17 fps, 29.92 tbr, 600 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-05-18T10:13:13.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 48 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-05-18T10:13:13.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Output #0, ipod, to '/Users/jmtek/Downloads/113_1684404795.m4a':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isommp41mp42\n",
      "    copyright-eng   : \n",
      "    copyright       : \n",
      "    encoder         : Lavf60.5.100\n",
      "  Stream #0:0(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 48 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2023-05-18T10:13:13.000000Z\n",
      "      handler_name    : Core Media Audio\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "[out#0/ipod @ 0x7fb28d80df00] video:0kB audio:242kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.158620%\n",
      "size=     250kB time=00:00:40.74 bitrate=  50.3kbits/s speed= 515x    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/jmtek/Downloads/113_1684404795.m4a')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "def separate_audio(video_path: str):\n",
    "    path = Path(video_path)\n",
    "    audio_name = path.stem + \".m4a\"\n",
    "    audio_path = path.parent / audio_name\n",
    "    subprocess.run(['ffmpeg', '-y', '-i', video_path, '-vn', '-acodec', 'copy', audio_path])\n",
    "\n",
    "    return audio_path\n",
    "\n",
    "separate_audio(\"/Users/jmtek/Downloads/113_1684404795.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
